{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers wikipedia-api\n"
      ],
      "metadata": {
        "id": "x20QZSW3eZ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "from transformers import BertForQuestionAnswering, BertTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def fetch_wikipedia_text(title):\n",
        "    try:\n",
        "        wiki = wikipediaapi.Wikipedia(\n",
        "            user_agent='42 Wikipedia Scraper/1.0',  # User agent must be specified\n",
        "            language='en',\n",
        "            extract_format=wikipediaapi.ExtractFormat.WIKI\n",
        "        )\n",
        "        page = wiki.page(title)\n",
        "        if page.exists():\n",
        "            return page.text\n",
        "        else:\n",
        "            print(f\"Error: Wikipedia page '{title}' not found.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching Wikipedia page: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "yLF9DkdOecD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def answer_question(question, text):\n",
        "    # Tokenize input question and text\n",
        "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "    # Perform question-answering\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract start and end scores from outputs\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    # Find the tokens with the highest start and end scores\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores) + 1  # Add 1 to include the last token\n",
        "\n",
        "    # Convert token IDs to actual tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
        "\n",
        "    # Combine tokens to form the answer\n",
        "    answer = tokenizer.convert_tokens_to_string(tokens[answer_start:answer_end])\n",
        "\n",
        "    # Post-process answer (remove special tokens and additional spaces)\n",
        "    answer = answer.replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
        "    return answer"
      ],
      "metadata": {
        "id": "TZygAiGJgoOD"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Wikipedia text (replace 'Chatbot' with your desired topic)\n",
        "article_title = \"Phrases from The Hitchhiker's Guide to the Galaxy\"\n",
        "article_text = fetch_wikipedia_text(article_title)\n",
        "\n",
        "# Example usage\n",
        "question = \"What is the Answer to the Ultimate Question of Life, the Universe, and Everything?\"\n",
        "\n",
        "answer = answer_question(question, article_text)\n",
        "print(\">===============================<\")\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)\n",
        "print(\">===============================<\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4SKPfIe2VF",
        "outputId": "1026da5b-06c7-48c4-9c0c-813b70f5c0eb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">===============================<\n",
            "Question: What is the Answer to the Ultimate Question of Life, the Universe, and Everything?\n",
            "Answer: 42\n",
            ">===============================<\n"
          ]
        }
      ]
    }
  ]
}