{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers wikipedia-api"
      ],
      "metadata": {
        "id": "x20QZSW3eZ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "from transformers import BertForQuestionAnswering, BertTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def fetch_wikipedia_text(title):\n",
        "    try:\n",
        "        wiki = wikipediaapi.Wikipedia(\n",
        "            user_agent='42 Wikipedia Scraper/1.0',\n",
        "            language='en',\n",
        "            extract_format=wikipediaapi.ExtractFormat.WIKI\n",
        "        )\n",
        "        page = wiki.page(title)\n",
        "        if page.exists():\n",
        "            return page.text\n",
        "        else:\n",
        "            print(f\"Error: Wikipedia page '{title}' not found.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching Wikipedia page: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLF9DkdOecD3",
        "outputId": "30ab3b4c-86ed-4920-d0ba-2cf9ecc4b9f1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, text):\n",
        "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores) + 1\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
        "    answer = tokenizer.convert_tokens_to_string(tokens[answer_start:answer_end])\n",
        "    answer = answer.replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
        "    return answer"
      ],
      "metadata": {
        "id": "TZygAiGJgoOD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_article_title = \"Phrases from The Hitchhiker's Guide to the Galaxy\"\n",
        "article_text = fetch_wikipedia_text(train_article_title)\n",
        "\n",
        "question = \"waht is The Answer to the Ultimate Question of Life, the Universe, and Everything?\"\n",
        "answer = answer_question(question, article_text)\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)\n",
        "print(\"---------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4SKPfIe2VF",
        "outputId": "d22e2f52-60d6-4561-e02f-72bfba9264fe"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "Question: waht is The Answer to the Ultimate Question of Life, the Universe, and Everything?\n",
            "Answer: 42\n",
            "---------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}